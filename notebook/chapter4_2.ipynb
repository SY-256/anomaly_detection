{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMFb3XHyXW/hSpkUyS2MN1A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SY-256/anomaly_detection/blob/main/notebook/chapter4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ホテリング理論による異常検知\n",
        "ホテリング理論は、解析計算に基づく理論の明快さや、統計ライブラリによる実装のしやすさから、基礎的な異常検知アルゴリズムの一つとして広く利用されている\n",
        "\n",
        "1変数のホテリング理論による異常検知をPythonで実装\n",
        "- A. データが正規分布に従うか\n",
        "- B. モデルの学習\n",
        "- C. 推論"
      ],
      "metadata": {
        "id": "zcToJ0GdAzJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. データが正規分布に従うか\n",
        "- ヒストグラムによる可視化\n",
        "- Q-Qプロットによる可視化\n",
        "- 正規性検定\n",
        "\n",
        "### ヒストグラムによる可視化\n",
        "- 山が一つ\n",
        "- 左右対称\n",
        "- 釣鐘形の分布形状\n",
        "- 裾が長すぎない（外れ値が少ない）"
      ],
      "metadata": {
        "id": "jC_sBgDzBQK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ghmagazine/python_anomaly_detection_book/refs/heads/main/notebooks/datasets/ch2_dataset_train.csv\")\n",
        "df_dropna = df.dropna(subset=[\"temp1\"]) # 欠損値削除\n",
        "df_normal = df_dropna[df_dropna[\"label\"] == \"normal\"] # 正常データのみ抽出\n",
        "x_train = df_normal[\"temp1\"].to_numpy() # numpy.ndarrayに変換\n",
        "\n",
        "# 変数\"temp1\"のヒストグラムを表示\n",
        "plt.hist(x=x_train, color=\"#888888\", bins=\"sturges\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R8WY8P49BvTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q-Qプロット\n",
        "- 正規性をシンプルに判断できる（データが正規分布に従うか）\n",
        "\n",
        "1. データを昇順ソートし、分位点を求める\n",
        "2. データに対して最尤推定で正規分布をフィッティングし、求めた正規分布の分位点を求める\n",
        "3. 1で求めたデータの分位点を縦軸、2で求めた正規分布の分位点を横軸にとり、散布図をプロットする（この散布図をQ-Qプロットとして用いる）\n",
        "4. 3で作成したQ-Qプロットがおおむね直線に沿っていれば、データが正規分布に従うとみなす"
      ],
      "metadata": {
        "id": "1UdIMVE_CnM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-Qプロット\n",
        "from scipy import stats\n",
        "\n",
        "stats.probplot(x_train, dist=\"norm\", plot=plt)"
      ],
      "metadata": {
        "id": "9lVtn6-dOUkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 多少のずれはあるものの、Q-Qプロットがおおむね直線に沿っており、データが正規分布に従っていると判断できる"
      ],
      "metadata": {
        "id": "cCZm8zKWOe74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 正規性検定\n",
        "- 定量的に正規性を判断できる\n",
        "- サンプルサイズが小さい場合：シャピロ-ウィルク検定\n",
        "- サンプルサイズが大きい場合：コルモゴロフ-スミルノフ検定\n",
        "\n",
        "正規性検定とは、データが正規分布に従っているかを統計的に検定する方法全般を指す"
      ],
      "metadata": {
        "id": "7W_YmFYHOzks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 正規性検定\n",
        "import numpy as np\n",
        "\n",
        "# Shapiro-Wilk検定\n",
        "stat, p = stats.shapiro(x_train)\n",
        "print(\"Shapiro-Wilk検定の統計量=%.3f, p値=%.3f\" % (stat, p))\n",
        "# Kolmogorov-Smirnov検定（平均と標準偏差を`args`引数に与える必要がある）\n",
        "mean = np.mean(x_train)\n",
        "std = np.std(x_train, ddof=1)\n",
        "stat, p = stats.kstest(x_train, stats.norm.cdf, args=(mean, std))\n",
        "print(\"Klomogorov-Smirnov検定の統計量=%.3f, p値=%.3f\" % (stat, p))"
      ],
      "metadata": {
        "id": "HwZ2z7Y8PVbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- これらの検定はデータが正規分布からサンプリングされたものであるという帰無仮説を用いている。\n",
        "- p値が有意水準を下回った際に、データが正規分布に従わないことは裏付けられるが、有意水準を上回ったからといって、データが正規分布に従うことを裏付けるわけではない。\n",
        "- 最終的にはヒストグラムやQ-Qプロットの当てはまりの良さなども加味して判断する。"
      ],
      "metadata": {
        "id": "kZ2J2USfQjxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデル学習\n",
        "1変数のホテリング理論では、サンプルサイズNの大小に応じて以下脳ように異常度\n",
        "\n",
        "<img src=\"https://latex.codecogs.com/svg.image?\n",
        "a(x) = \\Big(\\frac{x-\\hat{\\mu}}{\\hat{\\sigma}}\\Big)^2\n",
        "\" />\n",
        "\n",
        "が従う確率分布を使い分けます（$\\hat{\\mu}$は標本平均、$\\hat{\\sigma}$は標本標準偏差）。\n",
        "\n",
        "- サンプルサイズ$N$が**大きい**場合：異常度の分布は自由度1の**カイ二乗分布**に近似できる\n",
        "- サンプルサイズ$N$が**小さい**場合：異常度を$\\frac{N-1}{N+1}$倍した統計量は自由度$(1,N-1)$の**F分布**に従う\n",
        "\n",
        "カイ二乗分布とF分布の使い分けにおける$N$の明確な境界は決まっていないが、1変数においてはおおむね$N\\geq 100$であれば、カイ二乗分布による近似を利用したほうが良い\n",
        "\n",
        "### サンプルサイズ$N$が大きい場合の学習の実装\n",
        "\n",
        "サンプルサイズ$N$が大きい場合、異常度$a(x) = \\Big(\\frac{x-\\hat{\\mu}}{\\hat{\\sigma}}\\Big)^2$が自由度1のカイ二乗分布に従うことを前提に。以下のように正規分布（正常のモデル）のパラメータ$\\hat{\\mu}$（コード中の`mu`）、$\\hat{\\sigma}$（`sigma`）および異常度の閾値$a_{th}$（`a_th`）を求める。"
      ],
      "metadata": {
        "id": "bvzEwExsRUOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ホテリング理論による異常検知（サンプルサイズNが大きい場合）の実装例（学習）\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "##### 学習データの読み込みと前処理 #####\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ghmagazine/python_anomaly_detection_book/refs/heads/main/notebooks/datasets/ch2_dataset_train.csv\")\n",
        "# \"temp1\"変数に欠損があるデータを削除\n",
        "df_dropna = df.dropna(subset=[\"temp1\"])\n",
        "# 正常データのみ抽出\n",
        "df_normal = df_dropna[df_dropna[\"label\"] == \"normal\"]\n",
        "# \"temp1\"列のみ取り出してNumpyのndarray化し、学習データとする\n",
        "x_train = df_normal[\"temp1\"].to_numpy()\n",
        "\n",
        "##### 学習ステップ1. 正常のモデルを作成する #####\n",
        "mu = np.mean(x_train) # 標本平均μ\n",
        "sigma = np.std(x_train, ddof=0) # 標本標準偏差σを算出\n",
        "\n",
        "##### 学習ステップ2. 異常を表す指標（異常度）を定義する #####\n",
        "# 上のMarkdownで式を定義するのみ\n",
        "\n",
        "##### 学習ステップ3. 異常度に閾値を設ける #####\n",
        "TARGET_FP_RATE = 0.0027 # ターゲットとする誤報率（正規分布の3σ相当=0.0027）\n",
        "# 自由度1のカイ二乗分布の累積分布関数の逆関数（生存関数）から閾値を算出\n",
        "a_th = stats.chi2.ppf(1-TARGET_FP_RATE, df=1)\n",
        "\n",
        "##### 学習で求めたパラメータをすべて表示 #####\n",
        "print(f\"mu={mu}\")\n",
        "print(f\"sigma={sigma}\")\n",
        "print(f\"a_th={a_th}\")"
      ],
      "metadata": {
        "id": "a8ctdR_DYyY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## サンプルサイズ$N$が小さい場合の学習の実装\n",
        "\n",
        "サンプルサイズ$N$が小さい場合、異常度を$a(x) = \\Big(\\frac{x-\\hat{\\mu}}{\\hat{\\sigma}}\\Big)^2$を$\\frac{N-1}{N+1}$倍した統計量が自由度$(1, N-1)$のF分布に従うことを前提に、以下のように正規分布（正常のモデル）のパラメータ$\\hat{\\mu}$（コード中の`mu`）、$\\hat{\\sigma}$（`sigma`）および異常度の閾値$a_{th}$（`a_th`）を求める。"
      ],
      "metadata": {
        "id": "oguuDsYfamVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 途中まで同じ\n",
        "\n",
        "##### 学習ステップ3. 異常度に閾値を設ける #####\n",
        "TARGET_FP_RATE = 0.0027\n",
        "sample_size = len(x_train) # サンプルサイズN\n",
        "# 自由度（1, N-1）のF分布の累積密度関数の逆関数から閾値を算出\n",
        "a_th = (sample_size - 1) / (sample_size + 1) \\\n",
        "* stats.f.ppf(1-TARGET_FP_RATE, dfn=1, dfd=sample_size-1)\n",
        "\n",
        "##### 学習で求めたパラメータをすべて表示 #####\n",
        "print(f\"mu={mu}\")\n",
        "print(f\"sigma={sigma}\")\n",
        "print(f\"a_th={a_th}\")"
      ],
      "metadata": {
        "id": "a2AZgg5kb5L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "カイ二乗分布を使用した場合と比較して異常度の閾値がF分布を使用したほうが大きくなっており、誤報率を減らす方向（見逃し寄り）に閾値が設定されている。\n",
        "\n",
        "求めたパラメータ`mu`（標本平均$\\hat{\\mu}$）、`sigma`（標本標準偏差$\\hat{\\sigma}$）および異常度の閾値`a_th`（$a_{th}$）は設定ファイルなどに保存しておき、推論時に利用する"
      ],
      "metadata": {
        "id": "BtT8j33mcxT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論"
      ],
      "metadata": {
        "id": "2YKh7U9Jdh4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ホテリング理論による異常検知の実装例（推論）\n",
        "###### 学習で求めたパラメータをここに記載 ######\n",
        "MU=400.21552883243925 # 標本平均μ\n",
        "SIGMA=4.958226656997426 # 標本標準偏差σ\n",
        "A_TH=8.99986195674967 # 異常度のしきい値\n",
        "\n",
        "###### 推論データの読み込みと前処理 ######\n",
        "df_inference = pd.read_csv(\"https://raw.githubusercontent.com/ghmagazine/python_anomaly_detection_book/refs/heads/main/notebooks/datasets/ch2_dataset_inference.csv\")\n",
        "\n",
        "# \"temp1\"変数に欠損があるデータを削除\n",
        "df_inference_dropna = df_inference.dropna(subset=\"temp1\")\n",
        "# \"temp1\"列のみ取り出してNumPyのndarray化し、推論データとする\n",
        "x_inference = df_inference_dropna[\"temp1\"].to_numpy()\n",
        "\n",
        "###### 推論を実行 ######\n",
        "# 異常度を算出\n",
        "anomaly_scores = ((x_inference-MU)/SIGMA) ** 2\n",
        "# 閾値により異常の有無を判定\n",
        "pred = np.where(anomaly_scores > A_TH, \"anomaly\", \"normal\")\n",
        "# 推論結果を表示\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "15i8uMpgka2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "推論データの異常度のヒストグラムと閾値（Threshold）を重ねてプロット"
      ],
      "metadata": {
        "id": "8-GPelvTlj5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 推論データの異常度のヒストグラムと閾値を重ねてプロット（正常データと異常データで色分け）\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 異常度をDataFrameに列として追加\n",
        "df_inference_dropna[\"anomaly_score\"] = anomaly_scores\n",
        "# 描画用のFigureとAxesを生成\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))\n",
        "\n",
        "# 正常データのヒストグラム描画\n",
        "df_inference_norm = df_inference_dropna[df_inference_dropna[\"label\"] == \"normal\"]\n",
        "sns.histplot(data=df_inference_norm[\"anomaly_score\"], binwidth=1,\n",
        "             color=\"#bbbbbb\", ax=ax, stat=\"density\", label=\"normal\")\n",
        "# 異常データのヒストグラム\n",
        "df_inference_anom = df_inference_dropna[df_inference_dropna[\"label\"] == \"anomaly\"]\n",
        "sns.histplot(data=df_inference_anom[\"anomaly_score\"], binwidth=1,\n",
        "             color=\"#111111\", ax=ax,\n",
        "             stat=\"density\", label=\"anomaly\")\n",
        "\n",
        "# 閾値の線を描画\n",
        "ax.vlines(A_TH, 0, 0.3, color=\"black\", lw=2)\n",
        "ax.text(A_TH, 0.3, f\"Threshold={round(A_TH, 4)}\",\n",
        "        verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
        "# 凡例を表示\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dNWO00c9l4a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "検知精度は高くない"
      ],
      "metadata": {
        "id": "UGWE5GxYndcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用する変数を`temp1`から`temp2`に変更して、異常度を再度求めてみる"
      ],
      "metadata": {
        "id": "nKvaOPw9n3l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"temp2\"変数の推論データの異常度のヒストグラムと閾値を重ねてプロット\n",
        "\n",
        "###### 学習データの読み込みと前処理 ######\n",
        "# \"temp2\"列のみ取り出してNumPyのndarray化し、学習データとする\n",
        "x_train = df_normal[\"temp2\"].to_numpy()\n",
        "\n",
        "###### 学習ステップ1. 正常のモデル作成 ######\n",
        "mu = np.mean(x_train) # 標本平均μ\n",
        "sigma = np.std(x_train, ddof=0) # 標本標準偏差σ\n",
        "\n",
        "###### 学習ステップ2. 異常を表す指標（異常度）を定義する ######\n",
        "# 式のみ\n",
        "\n",
        "###### 学習ステップ3. 異常度に閾値を設ける ######\n",
        "TARGET_FP_RATE = 0.0027 # ターゲットとする誤報率（正規分布の3σ相当=0.0027）\n",
        "sample_size = len(x_train) # サンプルサイズN\n",
        "# 自由度1のカイ二乗分布の累積分布関数の逆関数から閾値算出\n",
        "a_th = stats.chi2.ppf(1-TARGET_FP_RATE, df=1)\n",
        "\n",
        "###### 推論データの前処理 ######\n",
        "# \"temp2\"変数に欠損があるデータを削除\n",
        "df_inference_dropna = df_inference.dropna(subset=\"temp2\")\n",
        "# \"temp2\"列のみ取り出してNumPyのndarray化し、推論データとする\n",
        "x_inference = df_inference_dropna[\"temp2\"].to_numpy()\n",
        "\n",
        "###### 推論を実行 ######\n",
        "# 異常度算出\n",
        "anomaly_scores = ((x_inference-mu) / sigma) ** 2\n",
        "# 閾値により異常の有無を判定\n",
        "pred = np.where(anomaly_scores > a_th, \"anomaly\", \"normal\")\n",
        "# 異常度をDataFrameに列として追加\n",
        "df_inference_dropna[\"anomaly_score\"] = anomaly_scores\n",
        "# 描画用のFigureとAxesを生成\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))\n",
        "\n",
        "# 正常データのヒストグラム描画\n",
        "df_inference_norm = df_inference_dropna[df_inference_dropna[\"label\"] == \"normal\"]\n",
        "sns.histplot(data=df_inference_norm[\"anomaly_score\"], binwidth=1,\n",
        "             color=\"#bbbbbb\", ax=ax,\n",
        "             stat=\"density\", label=\"normal\")\n",
        "# 異常データのヒストグラム描画\n",
        "df_inference_anom = df_inference_dropna[df_inference_dropna[\"label\"] == \"anomaly\"]\n",
        "sns.histplot(data=df_inference_anom[\"anomaly_score\"], binwidth=1,\n",
        "             color=\"#111111\", ax=ax,\n",
        "             stat=\"density\", label=\"anomaly\")\n",
        "# 閾値の線を描画\n",
        "ax.vlines(a_th, 0, 0.3, color=\"black\", lw=2)\n",
        "ax.text(a_th, 0.3, f\"Threshold={round(a_th, 4)}\",\n",
        "        verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
        "# 凡例を表示\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tQER9wA8oGrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "精度良く異常を検知できている"
      ],
      "metadata": {
        "id": "qTQ8yX_jtHxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 元の変数に閾値を設ける場合（異常度を使用しない）\n",
        "**異常度に閾値を設ける方法と比べて、以下のようなメリットがある**\n",
        "- ドメイン知識との親和性：温度や湿度など、意味が明確な変数に対して閾値を直接設定できるため、現場のエンジニアや運用担当者にも理解しやすい\n",
        "- 上下各方向の制御が可能：上限・下限に別々の閾値を設定できるため、異常の方向性（高すぎる・低すぎる）に応じて個別に感度を制御できる\n",
        "\n",
        "一方でこの方法では、**多変数への拡張が困難**であることや、複数の閾値を持つことから**解釈や運用の複雑性が上がる**ことに注意が必要"
      ],
      "metadata": {
        "id": "UjCcoObntSpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "サンプルサイズ$N$が大きい（正規分布に基づき閾値を算出する）場合の実装"
      ],
      "metadata": {
        "id": "Tf0mDGwatgLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ホテリング理論による異常検知\n",
        "###### 学習ステップ1. 正常のモデルを作成する ######\n",
        "mu = np.mean(x_train) # 標本平均μ\n",
        "sigma = np.std(x_train, ddof=1) # 標本標準偏差σ\n",
        "\n",
        "###### 学習ステップ2. 異常を表す指標（異常度）を定義する ######\n",
        "# 異常度は使用しない\n",
        "\n",
        "###### 学習ステップ3. 元の変数に閾値を設ける ######\n",
        "TARGET_FP_RATE = 0.0027 # ターゲットとする誤報率（正規分布の3σ相当=0.0027）\n",
        "# 正規分布の累積分布関数の逆関数から下限閾値算出（誤報率は2で割る）\n",
        "th_lower = stats.norm.ppf(TARGET_FP_RATE/2, loc=mu, scale=sigma)\n",
        "# 正規分布の累積分布関数の逆関数から上側閾値算出（誤報率は2で割る）\n",
        "th_upper = stats.norm.ppf(1 - TARGET_FP_RATE/2, loc=mu, scale=sigma)\n",
        "\n",
        "# 学習で求めたパラメータをすべて表示\n",
        "print(f\"mu={mu}\")\n",
        "print(f\"sigma={sigma}\")\n",
        "print(f\"th_lower={th_lower}\")\n",
        "print(f\"th_upper={th_upper}\")"
      ],
      "metadata": {
        "id": "5PCKZMsBuyf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "サンプルサイズ$N$が小さい（スチューデントのt分布に基づき閾値を算出する）場合、以下のように実装"
      ],
      "metadata": {
        "id": "SoTf8Oz_wHCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### 学習ステップ3. 異常度に閾値を設ける ######\n",
        "TARGET_FP_RATE = 0.0027\n",
        "sample_size = len(x_train)\n",
        "# 自由度N-1のt-分布の累積分布関数の逆関数から下側閾値算出（誤報率は2で割る）\n",
        "th_lower = mu + sigma * np.sqrt((sample_size+1) / (sample_size-1)) \\\n",
        "* stats.t.ppf(TARGET_FP_RATE/2, df=sample_size-1)\n",
        "# 自由度N-1の累積分布関数の逆関数から上側閾値算出（誤報率は2で割る）\n",
        "th_upper = mu + sigma * np.sqrt((sample_size+1) / (sample_size-1)) \\\n",
        "* stats.t.ppf(1 - TARGET_FP_RATE/2, df=sample_size-1)\n",
        "\n",
        "# 学習で求めたパラメータをすべて表示\n",
        "print(f\"mu={mu}\")\n",
        "print(f\"sigma={sigma}\")\n",
        "print(f\"th_lower={th_lower}\")\n",
        "print(f\"th_upper={th_upper}\")"
      ],
      "metadata": {
        "id": "us3KC6lHwVYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論\n",
        "異常度に閾値設ける場合との違いは、上下両方向に対してそれぞれ閾値を設定する"
      ],
      "metadata": {
        "id": "56ZiBQNWxHWh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5oyFXJnxhFS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM0ygHCtXCANmxTQaBeKbfC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SY-256/anomaly_detection/blob/main/notebook/chapter6_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 多変数のホテリング理論による異常検知\n",
        "\n",
        "多変数のホテリング理論による異常検知\n",
        "- A.変数選択\n",
        "- B.モデルの学習\n",
        "- C.推論"
      ],
      "metadata": {
        "id": "oRUC2xOD8K3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.変数選択"
      ],
      "metadata": {
        "id": "YI__eSjd_vYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ヒストグラムによる正常と異常の分離性の確認\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ghmagazine/python_anomaly_detection_book/refs/heads/main/notebooks/datasets/ch2_dataset_train.csv\")\n",
        "# \"label\"列を削除（数値型の列のみとする）\n",
        "df_val = df.drop(\"label\", axis=1)\n",
        "# 正常データのみ取り出す\n",
        "df_normal_val = df[df[\"label\"] == \"normal\"].drop(\"label\", axis=1)\n",
        "# 異常データのみ取り出す\n",
        "df_anomaly_val = df[df[\"label\"] == \"anomaly\"].drop(\"label\", axis=1)\n",
        "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(20, 4))\n",
        "\n",
        "# すべての変数をループで走査\n",
        "for i, colname in enumerate(df_normal_val.columns):\n",
        "    # 正常データのヒストグラム描画\n",
        "    sns.histplot(data=df_normal_val[colname], bins=\"sturges\",\n",
        "                 color=\"#bbbbbb\", ax=ax[i],\n",
        "                 stat=\"density\", label=\"normal\")\n",
        "    # 異常データのヒストグラム描画\n",
        "    sns.histplot(data=df_anomaly_val[colname], bins=\"sturges\",\n",
        "                 color=\"#111111\", ax=ax[i],\n",
        "                 stat=\"density\", label=\"anomaly\")\n",
        "\n",
        "    # 凡例を追加\n",
        "    ax[i].legend()\n",
        "    # 変数名を図のタイトルとして追加\n",
        "    ax[i].set_title(colname, fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-GtTi6Va8pBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "変数`temp1`、`temp2`、`temp3`において正常と異常の分布がある程度分離しているもの対し、`temp4`と`temp5`は両者の分布に目に見える差がない。よって、本データの異常の検知に寄与する可能性が低く、モデルの入力する必要性は低いと判断できる。"
      ],
      "metadata": {
        "id": "B_-DRqze-LDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 散布図（pairplot）による相関の確認\n",
        "sns.pairplot(\n",
        "    data=df,\n",
        "    vars=[\"temp1\", \"temp2\", \"temp3\"],\n",
        "    hue=\"label\",\n",
        "    palette=[\"#999999\", \"#111111\"]\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zIC3CAIH-2Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ホテリング理論は変数間の相関に比較的強いアルゴリズムであるので、弱相関程度であれば変数を削除しなくても良い。（今回は便宜上モデルの判定を可視化し易くするために、入力変数は`temp1`と`temp2`の2変数に絞る。"
      ],
      "metadata": {
        "id": "ruU5TwCm_Jlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.モデルの学習"
      ],
      "metadata": {
        "id": "QGm12tre_uSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習フェーズでは、最尤推定による多次元正規分布パラメータの推定、および異常度の閾値算出を実施"
      ],
      "metadata": {
        "id": "2N98WE_-_sfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 多変数のホテリング理論による異常検知の実装例（学習）\n",
        "# N >> Mが成り立つ場合の学習の実装（カイ二乗分布）\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "##### 学習データの読み込みと前処理 #####\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ghmagazine/python_anomaly_detection_book/refs/heads/main/notebooks/datasets/ch2_dataset_train.csv\")\n",
        "# \"temp2\"と\"temp1\"に欠損があるデータを削除\n",
        "df_dropna = df.dropna(subset=[\"temp1\", \"temp2\"], axis=0)\n",
        "# 正常データのみを抽出\n",
        "df_normal = df_dropna[df_dropna[\"label\"] == \"normal\"]\n",
        "# \"temp2\", \"temp1\"列のみ取り出してNumpyのndarray化し、学習データとする\n",
        "X_train = df_normal[[\"temp2\", \"temp1\"]].to_numpy()\n",
        "\n",
        "###### 学習ステップ1. 正常のモデルを作成 #####\n",
        "mu = np.mean(X_train, axis=0) # 標本平均ベクトルμを算出\n",
        "# 標本分散共分散行列Σを算出（転置と自由度ddofに注意）\n",
        "Sigma = np.cov(X_train.T, ddof=0)\n",
        "\n",
        "##### 学習ステップ2. 異常を表す指標（異常度）を定義する #####\n",
        "# 式のみの定義\n",
        "\n",
        "#### 学習ステップ3. 異常度に閾値を設ける #####\n",
        "TARGET_FP_RATE = 0.0027 # ターゲットとする誤報率（正規分布の3σ相当=0.0027）\n",
        "n_features = X_train.shape[1] # 変数の数M\n",
        "# 自由度（M）のカイ二乗分布の累積分布関数の逆関数から閾値を算出\n",
        "a_th = stats.chi2.ppf(1-TARGET_FP_RATE, df=n_features)\n",
        "\n",
        "##### 学習で求めたパラメータをすべて表示 #####\n",
        "print(f\"mu={mu}\")\n",
        "print(f\"Sigma={Sigma}\")\n",
        "print(f\"a_th={a_th}\")"
      ],
      "metadata": {
        "id": "EQ_pKlG3ABSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N >> Mが成り立たない場合の学習の実装（F分布 自由度(M, N - M)）\n",
        "##### 学習ステップ1. 正常のモデルを作成する #####\n",
        "mu = np.mean(X_train, axis=0) # 標本平均ベクトルμを算出\n",
        "# 標本分散共分散行列Σを算出\n",
        "Sigma = np.cov(X_train.T, ddof=0)\n",
        "\n",
        "##### 学習ステップ2. 異常を表す指標（異常度）を算出 #####\n",
        "# 式を定義するのみ\n",
        "\n",
        "##### 学習ステップ3. 異常度に閾値を設ける #####\n",
        "TARGET_FP_RATE = 0.0027 # ターゲットとする誤報率（正規分布の3σ相当=0.0027）\n",
        "sample_size = len(X_train) # サンプルサイズN\n",
        "n_features = X_train.shape[1] # 変数の数M\n",
        "# 自由度（M, N - M）のF分布の累積分布関数の逆関数から閾値を算出\n",
        "a_th = (sample_size+1)*n_features/(sample_size-n_features) \\\n",
        "* stats.f.ppf(1-TARGET_FP_RATE, dfn=n_features, dfd=sample_size-n_features)\n",
        "\n",
        "##### 学習で求めたパラメータを表示 #####\n",
        "print(f\"mu={mu}\")\n",
        "print(f\"Sigma={Sigma}\")\n",
        "print(f\"a_th={a_th}\")"
      ],
      "metadata": {
        "id": "V6_0HcGnCF56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "カイ二乗分布を使用した場合と比較して、異常度の閾値がやや大きくなっており、誤報率を減らす方向（見逃し寄り）に閾値が設定されてることがわかる（右側より）"
      ],
      "metadata": {
        "id": "WRj9jtkbDnsf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "at6_p2qsD96u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}